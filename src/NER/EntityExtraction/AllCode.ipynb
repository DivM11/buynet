{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entity_Extraction",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCZ5IwLoTRn6",
        "outputId": "43a02158-27bc-4522-a1a5-63b1ca990de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZD4aMxya9D9"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UeFGH84MaFG"
      },
      "source": [
        "import pandas as pd\n",
        "import gzip \n",
        "import numpy as np\n",
        "import spacy\n",
        "import json\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import ast\n",
        "import spacy\n",
        "from sklearn import cluster\n",
        "from collections import defaultdict\n",
        "from time import time\n",
        "\n",
        "NUM_CLUSTERS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-TbrDBsbBjs"
      },
      "source": [
        "# Link Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0kNnKDNMd8R",
        "outputId": "91bef10b-2008-4de0-af2c-0fc7601cf5c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWADZae3bEAy"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tpc66OAMhKo"
      },
      "source": [
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield eval(l)\n",
        "\n",
        "def getDF(path):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEGqFM9VMkLf"
      },
      "source": [
        "df = getDF('/content/drive/My Drive/reviews_Electronics_5.json.gz')[:1000]\n",
        "R = df.reviewText.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATrhI4cdMmcC",
        "outputId": "426b579d-6527-46fe-cb3f-ded5d31cfd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AO94DHGC771SJ</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>amazdnu</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Gotta have GPS!</td>\n",
              "      <td>1370131200</td>\n",
              "      <td>06 2, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMO214LNFCEI4</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>[12, 15]</td>\n",
              "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Very Disappointed</td>\n",
              "      <td>1290643200</td>\n",
              "      <td>11 25, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A3N7T0DY83Y4IG</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>C. A. Freeman</td>\n",
              "      <td>[43, 45]</td>\n",
              "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1st impression</td>\n",
              "      <td>1283990400</td>\n",
              "      <td>09 9, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1H8PY3QHMQQA0</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Dave M. Shaw \"mack dave\"</td>\n",
              "      <td>[9, 10]</td>\n",
              "      <td>Not going to write a long review, even thought...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Great grafics, POOR GPS</td>\n",
              "      <td>1290556800</td>\n",
              "      <td>11 24, 2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A24EV6RXELQZ63</td>\n",
              "      <td>0528881469</td>\n",
              "      <td>Wayne Smith</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I've had mine for a year and here's what we go...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Major issues, only excuses for support</td>\n",
              "      <td>1317254400</td>\n",
              "      <td>09 29, 2011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
              "0   AO94DHGC771SJ  0528881469  ...     1370131200   06 2, 2013\n",
              "1   AMO214LNFCEI4  0528881469  ...     1290643200  11 25, 2010\n",
              "2  A3N7T0DY83Y4IG  0528881469  ...     1283990400   09 9, 2010\n",
              "3  A1H8PY3QHMQQA0  0528881469  ...     1290556800  11 24, 2010\n",
              "4  A24EV6RXELQZ63  0528881469  ...     1317254400  09 29, 2011\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANpUfXBFdd8u"
      },
      "source": [
        "# Entity Extraction Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZo_R7-YbIg4"
      },
      "source": [
        "## Utils for Entity Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaImWMfkNb97"
      },
      "source": [
        "\n",
        "def init_spacy():\n",
        "    print(\"Loading Spacy\")\n",
        "    nlp = spacy.load(\"en_core_web_lg\")\n",
        "    # for w in stopwords:\n",
        "    #     nlp.vocab[w].is_stop = True\n",
        "    # for w in exclude_stopwords:\n",
        "    #     nlp.vocab[w].is_stop = False\n",
        "    return nlp\n",
        "\n",
        "\n",
        "def init_nltk():\n",
        "    print(\"\\nLoading NLTK....\")\n",
        "    try:\n",
        "        sid = SentimentIntensityAnalyzer()\n",
        "    except LookupError:\n",
        "        print(\"Installing SentimentAnalyzer\")\n",
        "        nltk.download(\"vader_lexicon\")\n",
        "        sid = SentimentIntensityAnalyzer()\n",
        "    print(\"NLTK successfully loaded\")\n",
        "    return sid\n",
        "\n",
        "\n",
        "def extract_aspects(reviews, nlp, sid):\n",
        "\n",
        "    # reviews = df[['review_id', 'review_body']]\n",
        "    # nlp = init_spacy()\n",
        "    # sid = init_nltk()\n",
        "\n",
        "    print(\"Entering Apply function!\")\n",
        "    aspect_list = reviews.apply(\n",
        "        lambda row: apply_extraction(row, nlp, sid), axis=1\n",
        "    )  # going through all the rows in the dataframe\n",
        "\n",
        "    return aspect_list\n",
        "\n",
        "\n",
        "def aspect_extraction(nlp, sid):\n",
        "    root = \"/content/drive/My Drive\"\n",
        "    print(\"=\" * 10)\n",
        "    print(df.columns)\n",
        "    # df = clean_data(df)\n",
        "    aspect_list = extract_aspects(df, nlp, sid)\n",
        "\n",
        "    # print(aspect_list)\n",
        "\n",
        "    return aspect_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33x8Dp5ZdG4l"
      },
      "source": [
        "## Entity Extraction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_GhL9hQMri0"
      },
      "source": [
        "prod_pronouns = [\"it\", \"this\", \"they\", \"these\"]\n",
        "avoid_neg = [\"price\", \"cost\"]\n",
        "\n",
        "def apply_extraction(row, nlp, sid):\n",
        "    review_body = row[\"reviewText\"]\n",
        "    review_id = row[\"reviewerID\"]\n",
        "    # verified = row[\"verified\"]\n",
        "    # overall = row[\"overall\"]\n",
        "    product_id = row[\"asin\"]\n",
        "    # summary = row[\"summary\"]\n",
        "    unixReviewTime = row[\"unixReviewTime\"]\n",
        "    # style = row[\"style\"]\n",
        "    # name = row[\"reviewerName\"]\n",
        "    # vote = row[\"vote\"]\n",
        "    doc = nlp(review_body)\n",
        "\n",
        "    # FIRST RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # RULE = M is child of A with a relationshio of amod\n",
        "    rule1_pairs = []\n",
        "    for token in doc:\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        if token.dep_ == \"amod\" and not token.is_stop:\n",
        "            M = token.text\n",
        "            A = token.head.text\n",
        "\n",
        "            # add adverbial modifier of adjective\n",
        "            # (e.g. 'most comfortable headphones')\n",
        "            M_children = token.children\n",
        "            for child_m in M_children:\n",
        "                if child_m.dep_ == \"advmod\":\n",
        "                    M_hash = child_m.text\n",
        "                    M = M_hash + \" \" + M\n",
        "                    break\n",
        "\n",
        "            # negation in adjective, the \"no\" keyword is a\n",
        "            # 'det' of the noun (e.g. no interesting characters)\n",
        "            if A not in avoid_neg:\n",
        "              A_children = token.head.children\n",
        "              for child_a in A_children:\n",
        "                  if child_a.dep_ == \"det\" and child_a.text == \"no\":\n",
        "                      neg_prefix = \"not\"\n",
        "                      M = neg_prefix + \" \" + M\n",
        "                      break\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            x = sid.polarity_scores(token.text)[\"compound\"]\n",
        "            rule1_pairs.append((A, M, x, 1))\n",
        "\n",
        "    # SECOND RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # Direct Object - A is a child of something\n",
        "    # with relationship of nsubj, while\n",
        "    # M is a child of the same something\n",
        "    # with relationship of dobj\n",
        "    # Assumption - A verb will have only one NSUBJ and DOBJ\n",
        "    add_neg_pfx = False\n",
        "    rule2_pairs = []\n",
        "    for token in doc:\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        add_neg_pfx = False\n",
        "        for child in children:\n",
        "            if child.dep_ == \"nsubj\" and not child.is_stop:\n",
        "                A = child.text\n",
        "                # check_spelling(child.text)\n",
        "            t1 = child.dep_ == \"dobj\"\n",
        "            t2 = child.pos_ == \"ADJ\"\n",
        "            if (t1 and t2) and not child.is_stop:\n",
        "                M = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"neg\":\n",
        "                neg_prefix = child.text\n",
        "                add_neg_pfx = True\n",
        "\n",
        "    if add_neg_pfx and M != \"999999\":\n",
        "        M = neg_prefix + \" \" + M\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            rule2_pairs.append((A, M, sid.polarity_scores(M)[\"compound\"], 2))\n",
        "\n",
        "    # THIRD RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # Adjectival Complement - A is a child\n",
        "    # of something with relationship of nsubj, while\n",
        "    # M is a child of the same something\n",
        "    # with relationship of acomp\n",
        "    # Assumption - A verb will have only one NSUBJ and DOBJ\n",
        "    # \"The sound of the speakers would be better.\n",
        "    #  The sound of the speakers could be better\"\n",
        "    # - handled using AUX dependency\n",
        "\n",
        "    rule3_pairs = []\n",
        "\n",
        "    for token in doc:\n",
        "\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        add_neg_pfx = False\n",
        "        for child in children:\n",
        "            if child.dep_ == \"nsubj\" and not child.is_stop:\n",
        "                A = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"acomp\" and not child.is_stop:\n",
        "                M = child.text\n",
        "\n",
        "            # example - 'this could have been better' -> (this, not better)\n",
        "            if child.dep_ == \"aux\" and child.tag_ == \"MD\":\n",
        "                neg_prefix = \"not\"\n",
        "                add_neg_pfx = True\n",
        "\n",
        "            if child.dep_ == \"neg\":\n",
        "                neg_prefix = child.text\n",
        "                add_neg_pfx = True\n",
        "\n",
        "        if add_neg_pfx and M != \"999999\":\n",
        "            M = neg_prefix + \" \" + M\n",
        "            # check_spelling(child.text)\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            rule3_pairs.append((A, M, sid.polarity_scores(M)[\"compound\"], 3))\n",
        "\n",
        "    # FOURTH RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # Adverbial modifier to a passive verb -\n",
        "    # A is a child of something with relationship\n",
        "    # of nsubjpass, while\n",
        "    # M is a child of the same something\n",
        "    # with relationship of advmod\n",
        "    # Assumption - A verb will have only one NSUBJ and DOBJ\n",
        "\n",
        "    rule4_pairs = []\n",
        "    for token in doc:\n",
        "\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        add_neg_pfx = False\n",
        "        for child in children:\n",
        "            if (\n",
        "                child.dep_ == \"nsubjpass\" or child.dep_ == \"nsubj\"\n",
        "            ) and not child.is_stop:\n",
        "                A = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"advmod\" and not child.is_stop:\n",
        "                M = child.text\n",
        "                M_children = child.children\n",
        "                for child_m in M_children:\n",
        "                    if child_m.dep_ == \"advmod\":\n",
        "                        M_hash = child_m.text\n",
        "                        M = M_hash + \" \" + child.text\n",
        "                        break\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"neg\":\n",
        "                neg_prefix = child.text\n",
        "                add_neg_pfx = True\n",
        "\n",
        "        if add_neg_pfx and M != \"999999\":\n",
        "            M = neg_prefix + \" \" + M\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            temp = sid.polarity_scores(M)[\"compound\"]\n",
        "            rule4_pairs.append((A, M, temp, 4))\n",
        "\n",
        "    # FIFTH RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # Complement of a copular verb - A is a\n",
        "    # child of M with relationship of nsubj, while\n",
        "    # M has a child with relationship of cop\n",
        "    # Assumption - A verb will have only one NSUBJ and DOBJ\n",
        "\n",
        "    rule5_pairs = []\n",
        "    for token in doc:\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        buf_var = \"999999\"\n",
        "        for child in children:\n",
        "            if child.dep_ == \"nsubj\" and not child.is_stop:\n",
        "                A = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"cop\" and not child.is_stop:\n",
        "                buf_var = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "        if A != \"999999\" and buf_var != \"999999\":\n",
        "            rule5_pairs.append(\n",
        "                (A, token.text, sid.polarity_scores(token.text)[\"compound\"], 5)\n",
        "            )\n",
        "\n",
        "    # SIXTH RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # Example - \"It ok\", \"ok\" is INTJ\n",
        "    # (interjections like bravo, great etc)\n",
        "\n",
        "    rule6_pairs = []\n",
        "    for token in doc:\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        if token.pos_ == \"INTJ\" and not token.is_stop:\n",
        "            for child in children:\n",
        "                if child.dep_ == \"nsubj\" and not child.is_stop:\n",
        "                    A = child.text\n",
        "                    M = token.text\n",
        "                    # check_spelling(child.text)\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            rule6_pairs.append((A, M, sid.polarity_scores(M)[\"compound\"], 6))\n",
        "\n",
        "    # SEVENTH RULE OF DEPENDANCY PARSE -\n",
        "    # M - Sentiment modifier || A - Aspect\n",
        "    # ATTR - link between a verb like\n",
        "    # 'be/seem/appear' and its complement\n",
        "    # Example: 'this is garbage' -> (this, garbage)\n",
        "\n",
        "    rule7_pairs = []\n",
        "    for token in doc:\n",
        "        children = token.children\n",
        "        A = \"999999\"\n",
        "        M = \"999999\"\n",
        "        add_neg_pfx = False\n",
        "        for child in children:\n",
        "            if child.dep_ == \"nsubj\" and not child.is_stop:\n",
        "                A = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if (child.dep_ == \"attr\") and not child.is_stop:\n",
        "                M = child.text\n",
        "                # check_spelling(child.text)\n",
        "\n",
        "            if child.dep_ == \"neg\":\n",
        "                neg_prefix = child.text\n",
        "                add_neg_pfx = True\n",
        "\n",
        "        if add_neg_pfx and M != \"999999\":\n",
        "            M = neg_prefix + \" \" + M\n",
        "\n",
        "        if A != \"999999\" and M != \"999999\":\n",
        "            rule7_pairs.append((A, M, sid.polarity_scores(M)[\"compound\"], 7))\n",
        "\n",
        "    aspects = []\n",
        "\n",
        "    aspects = (\n",
        "        rule1_pairs\n",
        "        + rule2_pairs\n",
        "        + rule3_pairs\n",
        "        + rule4_pairs\n",
        "        + rule5_pairs\n",
        "        + rule6_pairs\n",
        "        + rule7_pairs\n",
        "    )\n",
        "\n",
        "    # replace all instances of \"it\", \"this\" and \"they\" with \"product\"\n",
        "    aspects = [\n",
        "        (A, M, P, r) if A not in prod_pronouns else (\"product\", M, P, r)\n",
        "        for A, M, P, r in aspects\n",
        "    ]\n",
        "\n",
        "    dic = {\n",
        "        \"reviewText\": review_body,\n",
        "        \"reviewerID\": review_id,\n",
        "        # \"verified\": verified,\n",
        "        # \"overall\": overall,\n",
        "        \"asin\": product_id,\n",
        "        # \"summary\": summary,\n",
        "        \"unixReviewTime\": unixReviewTime,\n",
        "        \"aspect_pairs\": aspects,\n",
        "        # \"style\": style,\n",
        "        # \"reviewerName\": name,\n",
        "        # \"vote\": vote,\n",
        "    }\n",
        "\n",
        "    return dic\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFP72acqdLb8"
      },
      "source": [
        "## Making json file with entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxqnMtHJNs19",
        "outputId": "3f7a4a9b-af82-4f0c-8e22-91e42125b248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = init_spacy()\n",
        "sid = init_nltk()\n",
        "a = aspect_extraction(nlp, sid)\n",
        "a.to_json(\"Entity.json\", orient=\"split\", compression=\"infer\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Spacy\n",
            "\n",
            "Loading NLTK....\n",
            "Installing SentimentAnalyzer\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "NLTK successfully loaded\n",
            "==========\n",
            "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
            "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
            "      dtype='object')\n",
            "Entering Apply function!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lmUzZ_IdUVE"
      },
      "source": [
        "# Clustering Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnIVBMHqdtGn"
      },
      "source": [
        "## Loading entity data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7gODDfUOF6y"
      },
      "source": [
        "f = open(\"Entity.json\")\n",
        "reviews_data = json.load(f)[\"data\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-AaJhkvOcde",
        "outputId": "a059e36c-fcb8-4018-b635-c9c795d8160c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "reviews_data[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'asin': '0972683275',\n",
              " 'aspect_pairs': [['installation', 'simple', 0.0, 3]],\n",
              " 'reviewText': \"you can't beat the price and the installation was simple as can be. We installed it in our office and it is perfect! no problems and was completed in a matter of minutes\",\n",
              " 'reviewerID': 'A7EVWY97FPSIA',\n",
              " 'unixReviewTime': 1355097600}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSIuzWP0dzao"
      },
      "source": [
        "## Utils function for Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elJBWCuHOg_t"
      },
      "source": [
        "def get_unique_product_ids(reviews_data):\n",
        "    product_ids = []\n",
        "    product_ids = [r['asin'] for r in reviews_data]\n",
        "    return list(set(product_ids))\n",
        "\n",
        "def get_aspects(reviews_data):\n",
        "    aspects = []\n",
        "    for review in reviews_data:\n",
        "        aspect_pairs = review[\"aspect_pairs\"]\n",
        "        for noun,_,_,_ in aspect_pairs:\n",
        "            aspects.append(noun)\n",
        "    # aspects = [r['aspect_pairs'][0] for r in reviews_data]\n",
        "    return aspects\n",
        "\n",
        "def get_aspect_freq_map(aspects):\n",
        "    aspect_freq_map = defaultdict(int)\n",
        "    for asp in aspects:\n",
        "        aspect_freq_map[asp] += 1\n",
        "    return aspect_freq_map\n",
        "\n",
        "def get_unique_aspects(aspects):\n",
        "    unique_aspects = list(set(aspects)) # use this list for clustering\n",
        "    return unique_aspects\n",
        "\n",
        "\n",
        "def get_word_vectors(unique_aspects, nlp):\n",
        "    asp_vectors = []\n",
        "    for aspect in unique_aspects:\n",
        "        # print(aspect)\n",
        "        token = nlp(aspect)\n",
        "        asp_vectors.append(token.vector)\n",
        "    return asp_vectors\n",
        "\n",
        "def get_word_clusters(unique_aspects, nlp):\n",
        "    print(\"Found {} unique aspects for this product\".format(len(unique_aspects)))\n",
        "    asp_vectors = get_word_vectors(unique_aspects, nlp)\n",
        "    # n_clusters = min(NUM_CLUSTERS,len(unique_aspects))\n",
        "    if len(unique_aspects) <= NUM_CLUSTERS:\n",
        "        print(\"Too few aspects ({}) found. No clustering required...\".format(len(unique_aspects)))\n",
        "        return list(range(len(unique_aspects)))\n",
        "\n",
        "    print(\"Running k-means clustering...\")\n",
        "    n_clusters = NUM_CLUSTERS\n",
        "    kmeans = cluster.KMeans(n_clusters=n_clusters)\n",
        "    kmeans.fit(asp_vectors)\n",
        "    labels = kmeans.labels_\n",
        "    print(\"Finished running k-means clustering with {} labels\".format(len(labels)))\n",
        "    return labels\n",
        "\n",
        "def get_cluster_names_map(asp_to_cluster_map, aspect_freq_map):\n",
        "    cluster_id_to_name_map = defaultdict()\n",
        "    # cluster_to_asp_map = defaultdict()\n",
        "    n_clusters = len(set(asp_to_cluster_map.values()))\n",
        "    for i in range(n_clusters):\n",
        "        this_cluster_asp = [k for k,v in asp_to_cluster_map.items() if v == i]\n",
        "        filt_freq_map = {k:v for k,v in aspect_freq_map.items() if k in this_cluster_asp}\n",
        "        filt_freq_map = sorted(filt_freq_map.items(), key = lambda x: x[1], reverse = True)\n",
        "        cluster_id_to_name_map[i] = filt_freq_map[0][0]\n",
        "\n",
        "        # cluster_to_asp_map[i] = cluster_nouns\n",
        "\n",
        "    # print(cluster_to_asp_map)\n",
        "    return cluster_id_to_name_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcfZIyoKeUKc"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_WZ0FfOh4l"
      },
      "source": [
        "def add_clusters_to_reviews(reviews_data, nlp):\n",
        "    product_aspects = get_aspects(reviews_data)\n",
        "    print(\"Total aspects found: {}\".format(len(product_aspects)))\n",
        "    aspect_freq_map = get_aspect_freq_map(product_aspects)\n",
        "    unique_aspects = aspect_freq_map.keys()\n",
        "    print(\"Runnig clustering on {} unique aspects\".format(len(unique_aspects)))\n",
        "\n",
        "    aspect_labels = get_word_clusters(unique_aspects, nlp)\n",
        "    asp_to_cluster_map = dict(zip(unique_aspects, aspect_labels))\n",
        "    cluster_names_map = get_cluster_names_map(asp_to_cluster_map, aspect_freq_map)\n",
        "    updated_reviews = []\n",
        "    \n",
        "    m = {}\n",
        "    summ = {\"product_id\":reviews_data[0]['asin']}\n",
        "    for review in reviews_data:\n",
        "        result = []\n",
        "        aspect_pairs = review[\"aspect_pairs\"]\n",
        "        for noun,adj,polarity,rule  in aspect_pairs:\n",
        "            cluster_label_id = asp_to_cluster_map[noun]\n",
        "            cluster_label_name = cluster_names_map[cluster_label_id]\n",
        "            if noun in m:\n",
        "              m[cluster_label_name].append(polarity)\n",
        "            else:\n",
        "              m[cluster_label_name] = [polarity]\n",
        "            result.append({'noun':noun, 'adj':adj, 'rule':rule, 'polarity':polarity, 'cluster':cluster_label_name})\n",
        "\n",
        "        assert len(result) == len(aspect_pairs)\n",
        "\n",
        "        updated_reviews.append({'review_id':review['reviewerID'], 'product_id':review['asin'], 'aspect_pairs':result})\n",
        "    for key in m:\n",
        "      summ[key] = np.array(m[key]).mean()\n",
        "    return updated_reviews, [summ]\n",
        "\n",
        "def update_reviews_data(reviews_data, nlp):\n",
        "    updated_reviews = []\n",
        "    summ_reviews = []\n",
        "    product_ids = get_unique_product_ids(reviews_data)\n",
        "    print(\"Total number of unique products in this category: {}\".format(len(product_ids)))\n",
        "\n",
        "    no_asp_reviews = [r for r in reviews_data if len(r['aspect_pairs']) == 0]\n",
        "    print(\"Total reviews found with no aspect pairs: {}\".format(len(no_asp_reviews)))\n",
        "\n",
        "    for prod_id in product_ids:\n",
        "        print(\"\\nRunning clustering for product ID - {}\".format(prod_id))\n",
        "        this_product_reviews = [r for r in reviews_data if r['asin'] == prod_id]\n",
        "\n",
        "        this_product_upd_reviews, s = add_clusters_to_reviews(this_product_reviews, nlp)\n",
        "        updated_reviews.extend(this_product_upd_reviews)\n",
        "        summ_reviews.extend(s)\n",
        "    print(\"\\n----------------***----------------\")\n",
        "    print(\"Updating final results\")\n",
        "    with open('results_file.json', 'a') as f:\n",
        "        json.dump(updated_reviews,f)\n",
        "    with open('summ_file.json', 'a') as f:\n",
        "        json.dump(summ_reviews,f)\n",
        "\n",
        "    print(\"Finished writing results to json!!\")\n",
        "    print(\"----------------***----------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCFRSmMNeX15"
      },
      "source": [
        "## Calling Clustering Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OzjtPUOsza",
        "outputId": "485d1143-9ad0-434b-c366-5da3b8e656dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Running clustering...\")\n",
        "update_reviews_data(reviews_data, nlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running clustering...\n",
            "Total number of unique products in this category: 40\n",
            "Total reviews found with no aspect pairs: 109\n",
            "\n",
            "Running clustering for product ID - 1400532655\n",
            "Total aspects found: 1480\n",
            "Runnig clustering on 617 unique aspects\n",
            "Found 617 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 617 labels\n",
            "\n",
            "Running clustering for product ID - 9966338926\n",
            "Total aspects found: 34\n",
            "Runnig clustering on 22 unique aspects\n",
            "Found 22 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 22 labels\n",
            "\n",
            "Running clustering for product ID - 9573212900\n",
            "Total aspects found: 26\n",
            "Runnig clustering on 17 unique aspects\n",
            "Found 17 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 17 labels\n",
            "\n",
            "Running clustering for product ID - 3744295508\n",
            "Total aspects found: 34\n",
            "Runnig clustering on 26 unique aspects\n",
            "Found 26 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 26 labels\n",
            "\n",
            "Running clustering for product ID - 0528881469\n",
            "Total aspects found: 86\n",
            "Runnig clustering on 60 unique aspects\n",
            "Found 60 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 60 labels\n",
            "\n",
            "Running clustering for product ID - 1400501466\n",
            "Total aspects found: 541\n",
            "Runnig clustering on 277 unique aspects\n",
            "Found 277 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 277 labels\n",
            "\n",
            "Running clustering for product ID - 9575871979\n",
            "Total aspects found: 116\n",
            "Runnig clustering on 76 unique aspects\n",
            "Found 76 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 76 labels\n",
            "\n",
            "Running clustering for product ID - 1400501520\n",
            "Total aspects found: 176\n",
            "Runnig clustering on 121 unique aspects\n",
            "Found 121 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 121 labels\n",
            "\n",
            "Running clustering for product ID - 3930992868\n",
            "Total aspects found: 23\n",
            "Runnig clustering on 16 unique aspects\n",
            "Found 16 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 16 labels\n",
            "\n",
            "Running clustering for product ID - 8862936826\n",
            "Total aspects found: 78\n",
            "Runnig clustering on 55 unique aspects\n",
            "Found 55 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 55 labels\n",
            "\n",
            "Running clustering for product ID - 1400698987\n",
            "Total aspects found: 157\n",
            "Runnig clustering on 112 unique aspects\n",
            "Found 112 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 112 labels\n",
            "\n",
            "Running clustering for product ID - 9966694544\n",
            "Total aspects found: 30\n",
            "Runnig clustering on 22 unique aspects\n",
            "Found 22 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 22 labels\n",
            "\n",
            "Running clustering for product ID - 1400599997\n",
            "Total aspects found: 867\n",
            "Runnig clustering on 375 unique aspects\n",
            "Found 375 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 375 labels\n",
            "\n",
            "Running clustering for product ID - 9966569863\n",
            "Total aspects found: 10\n",
            "Runnig clustering on 7 unique aspects\n",
            "Found 7 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 7 labels\n",
            "\n",
            "Running clustering for product ID - 0972683275\n",
            "Total aspects found: 794\n",
            "Runnig clustering on 311 unique aspects\n",
            "Found 311 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 311 labels\n",
            "\n",
            "Running clustering for product ID - 6301977173\n",
            "Total aspects found: 56\n",
            "Runnig clustering on 48 unique aspects\n",
            "Found 48 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 48 labels\n",
            "\n",
            "Running clustering for product ID - 9966541551\n",
            "Total aspects found: 13\n",
            "Runnig clustering on 10 unique aspects\n",
            "Found 10 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 10 labels\n",
            "\n",
            "Running clustering for product ID - 1615527613\n",
            "Total aspects found: 17\n",
            "Runnig clustering on 9 unique aspects\n",
            "Found 9 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 9 labels\n",
            "\n",
            "Running clustering for product ID - 7799813393\n",
            "Total aspects found: 25\n",
            "Runnig clustering on 20 unique aspects\n",
            "Found 20 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 20 labels\n",
            "\n",
            "Running clustering for product ID - 9876050621\n",
            "Total aspects found: 5\n",
            "Runnig clustering on 4 unique aspects\n",
            "Found 4 unique aspects for this product\n",
            "Too few aspects (4) found. No clustering required...\n",
            "\n",
            "Running clustering for product ID - 9983891204\n",
            "Total aspects found: 33\n",
            "Runnig clustering on 19 unique aspects\n",
            "Found 19 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 19 labels\n",
            "\n",
            "Running clustering for product ID - 0594481813\n",
            "Total aspects found: 24\n",
            "Runnig clustering on 20 unique aspects\n",
            "Found 20 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 20 labels\n",
            "\n",
            "Running clustering for product ID - 8918010656\n",
            "Total aspects found: 64\n",
            "Runnig clustering on 43 unique aspects\n",
            "Found 43 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 43 labels\n",
            "\n",
            "Running clustering for product ID - 140053271X\n",
            "Total aspects found: 717\n",
            "Runnig clustering on 315 unique aspects\n",
            "Found 315 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 315 labels\n",
            "\n",
            "Running clustering for product ID - 9043413585\n",
            "Total aspects found: 39\n",
            "Runnig clustering on 27 unique aspects\n",
            "Found 27 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 27 labels\n",
            "\n",
            "Running clustering for product ID - 3936710058\n",
            "Total aspects found: 10\n",
            "Runnig clustering on 7 unique aspects\n",
            "Found 7 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 7 labels\n",
            "\n",
            "Running clustering for product ID - 9573212919\n",
            "Total aspects found: 123\n",
            "Runnig clustering on 64 unique aspects\n",
            "Found 64 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 64 labels\n",
            "\n",
            "Running clustering for product ID - 9625993428\n",
            "Total aspects found: 100\n",
            "Runnig clustering on 59 unique aspects\n",
            "Found 59 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 59 labels\n",
            "\n",
            "Running clustering for product ID - 1400699169\n",
            "Total aspects found: 224\n",
            "Runnig clustering on 137 unique aspects\n",
            "Found 137 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 137 labels\n",
            "\n",
            "Running clustering for product ID - 1400501776\n",
            "Total aspects found: 224\n",
            "Runnig clustering on 151 unique aspects\n",
            "Found 151 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 151 labels\n",
            "\n",
            "Running clustering for product ID - 9862510447\n",
            "Total aspects found: 10\n",
            "Runnig clustering on 9 unique aspects\n",
            "Found 9 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 9 labels\n",
            "\n",
            "Running clustering for product ID - 9983891212\n",
            "Total aspects found: 204\n",
            "Runnig clustering on 98 unique aspects\n",
            "Found 98 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 98 labels\n",
            "\n",
            "Running clustering for product ID - 7214047977\n",
            "Total aspects found: 32\n",
            "Runnig clustering on 21 unique aspects\n",
            "Found 21 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 21 labels\n",
            "\n",
            "Running clustering for product ID - 0594451647\n",
            "Total aspects found: 19\n",
            "Runnig clustering on 16 unique aspects\n",
            "Found 16 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 16 labels\n",
            "\n",
            "Running clustering for product ID - 7507825604\n",
            "Total aspects found: 13\n",
            "Runnig clustering on 13 unique aspects\n",
            "Found 13 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 13 labels\n",
            "\n",
            "Running clustering for product ID - 1400532620\n",
            "Total aspects found: 666\n",
            "Runnig clustering on 318 unique aspects\n",
            "Found 318 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 318 labels\n",
            "\n",
            "Running clustering for product ID - 1400532736\n",
            "Total aspects found: 164\n",
            "Runnig clustering on 103 unique aspects\n",
            "Found 103 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 103 labels\n",
            "\n",
            "Running clustering for product ID - 8862935293\n",
            "Total aspects found: 34\n",
            "Runnig clustering on 24 unique aspects\n",
            "Found 24 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 24 labels\n",
            "\n",
            "Running clustering for product ID - 9981739588\n",
            "Total aspects found: 20\n",
            "Runnig clustering on 18 unique aspects\n",
            "Found 18 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 18 labels\n",
            "\n",
            "Running clustering for product ID - 9888002198\n",
            "Total aspects found: 108\n",
            "Runnig clustering on 64 unique aspects\n",
            "Found 64 unique aspects for this product\n",
            "Running k-means clustering...\n",
            "Finished running k-means clustering with 64 labels\n",
            "\n",
            "----------------***----------------\n",
            "Updating final results\n",
            "Finished writing results to json!!\n",
            "----------------***----------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS4eZgpUXUkC",
        "outputId": "ca7ce96d-de61-455e-ee92-c16df034cdbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  Entity.json  results_file.json  \u001b[01;34msample_data\u001b[0m/  summ_file.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WimmuA5rXbsC"
      },
      "source": [
        "f = open(\"results_file.json\")\n",
        "data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "airU6mXmng5r",
        "outputId": "1bdd25df-1234-4684-da69-199032758c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aspect_pairs': [{'adj': 'very bad',\n",
              "   'cluster': 'life',\n",
              "   'noun': 'way',\n",
              "   'polarity': -0.5423,\n",
              "   'rule': 1},\n",
              "  {'adj': 'loaded',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'covers',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'corrupted',\n",
              "   'cluster': 'tablet',\n",
              "   'noun': 'freezes',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'hardline',\n",
              "   'cluster': 'price',\n",
              "   'noun': 'marketing',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'oriented',\n",
              "   'cluster': 'price',\n",
              "   'noun': 'marketing',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'different',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'book',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'phoney',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'cover',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'commercial',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'cover',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'compromised',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'reader',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'compromised',\n",
              "   'cluster': 'tablet',\n",
              "   'noun': 'tablet',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'GOOD',\n",
              "   'cluster': 'books',\n",
              "   'noun': 'reader',\n",
              "   'polarity': 0.4404,\n",
              "   'rule': 1},\n",
              "  {'adj': 'real',\n",
              "   'cluster': 'tablet',\n",
              "   'noun': 'tablet',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 1},\n",
              "  {'adj': 'quirky',\n",
              "   'cluster': 'screen',\n",
              "   'noun': 'screen',\n",
              "   'polarity': 0.0,\n",
              "   'rule': 3}],\n",
              " 'product_id': '1400532655',\n",
              " 'review_id': 'A3MNFT5VFJ2V0V'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5wrUvn8mhD1"
      },
      "source": [
        "f = open(\"summ_file.json\")\n",
        "data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNoZBVThXoAl",
        "outputId": "0a865382-a24a-425a-d3e9-052b887cc790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[12]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B&N': 0.5719,\n",
              " 'books': 0.0,\n",
              " 'for': 0.0,\n",
              " 'library': -0.28595,\n",
              " 'product_id': '1400599997',\n",
              " 'screen': -0.22925}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}